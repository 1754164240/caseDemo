# éœ€æ±‚å¯¼å…¥åç”Ÿæˆæ¡ˆä¾‹çš„å®Œæ•´æµç¨‹

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **æœ€åæ›´æ–°**: 2026-02-05
> **é€‚ç”¨ç³»ç»Ÿ**: æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹å¹³å° v1.3+

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†ä»éœ€æ±‚æ–‡æ¡£ä¸Šä¼ åˆ°è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„å®Œæ•´æŠ€æœ¯æµç¨‹ã€‚

---

## ğŸ“‹ æµç¨‹æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éœ€æ±‚æ–‡æ¡£ä¸Šä¼  â”‚ -> â”‚  æ–‡æ¡£è§£æ   â”‚ -> â”‚ æ–‡æœ¬å‘é‡åŒ–  â”‚ -> â”‚ æµ‹è¯•ç‚¹ç”Ÿæˆ  â”‚ -> â”‚ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ â”‚ -> â”‚ å¹³å°é›†æˆåˆ›å»º â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                  â†“                  â†“                  â†“                  â†“                  â†“
   å‰ç«¯ä¸Šä¼             å¤šæ ¼å¼              Milvus             AIåˆ†æ             RAGå¢å¼º            å¹³å°API
   ä¿å­˜æ•°æ®åº“          è§£ææ–‡æœ¬            å­˜å‚¨å‘é‡           LLMæ¨ç†            ä¸Šä¸‹æ–‡             åˆ›å»ºç”¨ä¾‹
```

**æ ¸å¿ƒæŠ€æœ¯æ ˆ**:
- **æ–‡æ¡£è§£æ**: LangChain + python-docx + PyPDF2 + openpyxl
- **å‘é‡æ•°æ®åº“**: Milvus + ç¡…åŸºæµåŠ¨åµŒå…¥ (BAAI/bge-large-zh-v1.5)
- **AIæ¨ç†**: OpenAI API / å…¼å®¹æœåŠ¡ + LangChain 1.0+
- **å®æ—¶é€šçŸ¥**: WebSocket (JWTè®¤è¯)
- **å¹³å°é›†æˆ**: REST API + è¶…æ—¶ä¿æŠ¤

---

## ğŸ”„ è¯¦ç»†æµç¨‹è¯´æ˜

### é˜¶æ®µ 1: éœ€æ±‚æ–‡æ¡£ä¸Šä¼ ä¸è§£æ

#### 1.1 APIå…¥å£

**ç«¯ç‚¹**: `POST /api/v1/requirements/`
**ä»£ç ä½ç½®**: [backend/app/api/v1/endpoints/requirements.py](../backend/app/api/v1/endpoints/requirements.py)

**è¯·æ±‚å‚æ•°**:
```json
{
  "file": "multipart/form-data",
  "title": "éœ€æ±‚æ–‡æ¡£æ ‡é¢˜",
  "description": "éœ€æ±‚æè¿°ï¼ˆå¯é€‰ï¼‰"
}
```

**å“åº”æ•°æ®**:
```json
{
  "id": 1,
  "title": "éœ€æ±‚æ–‡æ¡£æ ‡é¢˜",
  "file_name": "éœ€æ±‚æ–‡æ¡£.docx",
  "file_path": "/uploads/xxxx.docx",
  "status": "pending",
  "created_at": "2026-02-05T10:00:00"
}
```

#### 1.2 æ–‡æ¡£è§£æå¤„ç†

**å¤„ç†æœåŠ¡**: [backend/app/services/document_parser.py](../backend/app/services/document_parser.py)

**æ”¯æŒæ ¼å¼**:
- âœ… Wordæ–‡æ¡£ (`.docx`)
- âœ… PDFæ–‡ä»¶ (`.pdf`)
- âœ… æ–‡æœ¬æ–‡ä»¶ (`.txt`)
- âœ… Excelè¡¨æ ¼ (`.xls`, `.xlsx`)

**è§£æç­–ç•¥** (ä¸‰å±‚å›é€€æœºåˆ¶):

```python
# ç¬¬ä¸€å±‚: LangChainå·¥å…·è§£æ
try:
    if file_extension == '.docx':
        loader = Docx2txtLoader(file_path)
    elif file_extension == '.pdf':
        loader = PyPDFLoader(file_path)
    elif file_extension == '.txt':
        loader = TextLoader(file_path)
    elif file_extension in ['.xls', '.xlsx']:
        loader = UnstructuredExcelLoader(file_path)

    documents = loader.load()
    content = "\n".join([doc.page_content for doc in documents])

except Exception as e:
    # ç¬¬äºŒå±‚: LangChain Unstructuredè§£æ
    try:
        loader = UnstructuredFileLoader(file_path)
        documents = loader.load()
        content = "\n".join([doc.page_content for doc in documents])

    except Exception as e:
        # ç¬¬ä¸‰å±‚: åŸç”ŸPythonåº“è§£æ
        if file_extension == '.docx':
            content = parse_docx_native(file_path)
        elif file_extension == '.pdf':
            content = parse_pdf_native(file_path)
        # ...
```

#### 1.3 DOCXç‰¹æ®Šå¤„ç†

**å¢å¼ºåŠŸèƒ½**:
- æå–æ®µè½æ–‡æœ¬
- æå–è¡¨æ ¼å†…å®¹
- æå–é¡µçœ‰é¡µè„š
- æå–æ–‡æœ¬æ¡†å†…å®¹
- ä½¿ç”¨XMLç›´æ¥è§£æå¤æ‚æ ¼å¼

**ä»£ç ç¤ºä¾‹**:
```python
def parse_docx_native(file_path: str) -> str:
    doc = Document(file_path)
    content = []

    # æå–æ®µè½
    for para in doc.paragraphs:
        if para.text.strip():
            content.append(para.text)

    # æå–è¡¨æ ¼
    for table in doc.tables:
        for row in table.rows:
            row_text = ' | '.join(cell.text for cell in row.cells)
            content.append(row_text)

    # æå–é¡µçœ‰é¡µè„š
    for section in doc.sections:
        header = section.header
        for para in header.paragraphs:
            if para.text.strip():
                content.append(para.text)

    # XMLè§£ææ–‡æœ¬æ¡†
    xml_content = doc.element.xml
    # ... æå–æ–‡æœ¬æ¡†å†…å®¹

    return "\n".join(content)
```

#### 1.4 Excelç‰¹æ®Šå¤„ç†

**æ™ºèƒ½è¡¨å¤´è¯†åˆ«**:
```python
def parse_excel_native(file_path: str) -> str:
    wb = openpyxl.load_workbook(file_path)
    content = []

    for sheet in wb.worksheets:
        # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
        headers = [cell.value for cell in sheet[1]]

        empty_row_count = 0
        for row in sheet.iter_rows(min_row=2):
            row_values = [cell.value for cell in row]

            # é˜²æ­¢å¤§æ–‡ä»¶å¡æ­»: è¿ç»­2000ç©ºè¡Œè‡ªåŠ¨åœæ­¢
            if all(v is None or str(v).strip() == '' for v in row_values):
                empty_row_count += 1
                if empty_row_count > 2000:
                    break
                continue

            # æ ¼å¼åŒ–ä¸º "åˆ—å: å€¼"
            row_data = []
            for header, value in zip(headers, row_values):
                if header and value:
                    row_data.append(f"{header}: {value}")

            content.append(' | '.join(row_data))

    return "\n".join(content)
```

#### 1.5 è¾“å‡ºç»“æœ

è§£æåçš„çº¯æ–‡æœ¬å†…å®¹å­˜å‚¨åˆ°æ•°æ®åº“ `requirements` è¡¨:

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `id` | Integer | ä¸»é”® |
| `title` | String | éœ€æ±‚æ ‡é¢˜ |
| `file_name` | String | åŸå§‹æ–‡ä»¶å |
| `file_path` | String | æ–‡ä»¶å­˜å‚¨è·¯å¾„ |
| `content` | Text | è§£æåçš„æ–‡æœ¬å†…å®¹ |
| `status` | String | å¤„ç†çŠ¶æ€ (pending/processing/completed) |
| `user_id` | Integer | ç”¨æˆ·ID |
| `created_at` | DateTime | åˆ›å»ºæ—¶é—´ |

---

### é˜¶æ®µ 2: æ–‡æ¡£å‘é‡åŒ–ä¸çŸ¥è¯†åº“æ„å»º

#### 2.1 å¤„ç†æœåŠ¡

**ä»£ç ä½ç½®**: [backend/app/services/document_embedding_service.py](../backend/app/services/document_embedding_service.py)

**æ ¸å¿ƒå‚æ•°**:
```python
CHUNK_SIZE = 500           # æ¯æ®µæ–‡æœ¬å¤§å°
CHUNK_OVERLAP = 100        # æ®µè½é‡å  (ä¿è¯è¯­ä¹‰è¿ç»­æ€§)
EMBEDDING_MODEL = "BAAI/bge-large-zh-v1.5"  # ç¡…åŸºæµåŠ¨ä¸­æ–‡å‘é‡æ¨¡å‹
EMBEDDING_DIMENSION = 1536  # å‘é‡ç»´åº¦
```

#### 2.2 æ–‡æœ¬æ™ºèƒ½åˆ‡åˆ†

**ä½¿ç”¨ RecursiveCharacterTextSplitter**:
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100,
    separators=[
        "\n\n",  # æ®µè½åˆ†éš”ç¬¦
        "\n",    # æ¢è¡Œç¬¦
        "ã€",    # ä¸­æ–‡é¡¿å·
        "ï¼Œ",    # ä¸­æ–‡é€—å·
        "ï¼›",    # ä¸­æ–‡åˆ†å·
        ".",     # è‹±æ–‡å¥å·
        "!",     # æ„Ÿå¹å·
        "?",     # é—®å·
        ";",     # è‹±æ–‡åˆ†å·
        "ï¼š",    # ä¸­æ–‡å†’å·
        " ",     # ç©ºæ ¼
        ""       # å­—ç¬¦çº§åˆ«
    ]
)

chunks = text_splitter.split_text(document_content)
```

**åˆ‡åˆ†ç¤ºä¾‹**:
```
åŸæ–‡ (1200å­—ç¬¦):
"ä¿é™©äº§å“æŠ•ä¿è§„åˆ™ï¼š1. æŠ•ä¿å¹´é¾„ï¼š18-65å‘¨å²ï¼›2. ç¼´è´¹æ–¹å¼ï¼šæœˆç¼´ã€å­£ç¼´ã€å¹´ç¼´..."

åˆ‡åˆ†ç»“æœ:
[ç‰‡æ®µ 1] (500å­—ç¬¦): "ä¿é™©äº§å“æŠ•ä¿è§„åˆ™ï¼š1. æŠ•ä¿å¹´é¾„ï¼š18-65å‘¨å²ï¼›2. ç¼´è´¹æ–¹å¼ï¼š..."
[ç‰‡æ®µ 2] (500å­—ç¬¦): "...ç¼´è´¹æ–¹å¼ï¼šæœˆç¼´ã€å­£ç¼´ã€å¹´ç¼´ï¼›3. ä¿é™©æœŸé—´ï¼š10å¹´ã€20å¹´..."
[ç‰‡æ®µ 3] (200å­—ç¬¦): "...ä¿é™©æœŸé—´ï¼š10å¹´ã€20å¹´ã€30å¹´ã€ç»ˆèº«..."
```

#### 2.3 æ‰¹é‡å‘é‡åŒ–

**è°ƒç”¨ç¡…åŸºæµåŠ¨API**:
```python
async def generate_embeddings(texts: List[str]) -> List[List[float]]:
    url = f"{EMBEDDING_API_BASE}/embeddings"
    headers = {
        "Authorization": f"Bearer {EMBEDDING_API_KEY}",
        "Content-Type": "application/json"
    }

    batch_size = 100  # åˆå§‹æ‰¹é‡å¤§å°
    all_embeddings = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]

        try:
            response = requests.post(
                url,
                headers=headers,
                json={
                    "model": EMBEDDING_MODEL,
                    "input": batch
                },
                timeout=30
            )

            if response.status_code == 413:
                # æ™ºèƒ½é”™è¯¯å¤„ç†: é‡åˆ°413é”™è¯¯è‡ªåŠ¨é™ä½batch_size
                logger.warning(f"æ‰¹é‡å¤§å° {batch_size} è¿‡å¤§, å‡åŠé‡è¯•")
                batch_size = batch_size // 2
                continue

            data = response.json()
            embeddings = [item['embedding'] for item in data['data']]
            all_embeddings.extend(embeddings)

        except Exception as e:
            logger.error(f"å‘é‡åŒ–å¤±è´¥: {e}")
            # è¶…é•¿æ–‡æœ¬è‡ªåŠ¨æ‹†åˆ†
            if len(batch) > 1:
                batch_size = max(1, batch_size // 2)
                continue

    return all_embeddings
```

#### 2.4 å†™å…¥Milvuså‘é‡æ•°æ®åº“

**é›†åˆç»“æ„** (Collection Schema):
```python
from pymilvus import CollectionSchema, FieldSchema, DataType

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="requirement_id", dtype=DataType.INT64),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema(name="chunk_index", dtype=DataType.INT64)
]

schema = CollectionSchema(fields, description="éœ€æ±‚æ–‡æ¡£çŸ¥è¯†åº“")
collection = Collection(name="requirement_knowledge", schema=schema)

# åˆ›å»ºç´¢å¼• (IVF_FLAT)
index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {"nlist": 128}
}
collection.create_index(field_name="embedding", index_params=index_params)
```

**æ’å…¥æ•°æ®**:
```python
entities = [
    [1, 1, 1, ...],                           # requirement_id
    ["æ–‡æœ¬ç‰‡æ®µ1", "æ–‡æœ¬ç‰‡æ®µ2", ...],            # text
    [[0.1, 0.2, ...], [0.3, 0.4, ...], ...],  # embedding (1536ç»´å‘é‡)
    [0, 1, 2, ...]                            # chunk_index
]

collection.insert(entities)
collection.load()  # åŠ è½½åˆ°å†…å­˜
```

#### 2.5 æ„å»ºAIä¸Šä¸‹æ–‡

**æ™ºèƒ½æŠ½æ ·ç­–ç•¥**:
```python
def build_ai_context(requirement_id: int, max_length: int = 8000) -> str:
    # ä»Milvusæ£€ç´¢æ‰€æœ‰æ–‡æ¡£ç‰‡æ®µ
    collection = Collection("requirement_knowledge")
    results = collection.query(
        expr=f"requirement_id == {requirement_id}",
        output_fields=["text", "chunk_index"]
    )

    # æŒ‰chunk_indexæ’åº
    chunks = sorted(results, key=lambda x: x['chunk_index'])

    # æ™ºèƒ½æŠ½æ ·: é¿å…è¶…å‡ºLLM Tokené™åˆ¶
    total_text = ""
    total_length = 0
    step = max(1, len(chunks) // 10)  # æœ€å¤šæŠ½æ ·10ä¸ªç‰‡æ®µ

    for i, chunk in enumerate(chunks[::step]):
        fragment = f"[ç‰‡æ®µ {i+1}/{len(chunks)}]\n{chunk['text']}\n\n"
        if total_length + len(fragment) > max_length:
            break
        total_text += fragment
        total_length += len(fragment)

    return total_text
```

#### 2.6 WebSocketé€šçŸ¥

**é€šçŸ¥ç±»å‹**: `knowledge_base_completed`

```python
await websocket_manager.broadcast(
    user_id=current_user.id,
    message={
        "type": "knowledge_base_completed",
        "requirement_id": requirement_id,
        "chunks_count": len(chunks),
        "status": "success"
    }
)
```

---

### é˜¶æ®µ 3: æµ‹è¯•ç‚¹ç”Ÿæˆ (AIåˆ†æ)

#### 3.1 APIç«¯ç‚¹

**ç«¯ç‚¹**: `POST /api/v1/test-points/generate`
**ä»£ç ä½ç½®**: [backend/app/api/v1/endpoints/test_points.py](../backend/app/api/v1/endpoints/test_points.py)

**è¯·æ±‚å‚æ•°**:
```json
{
  "requirement_id": 1,
  "model_config_id": 1  // å¯é€‰, æŒ‡å®šæ¨¡å‹é…ç½®
}
```

#### 3.2 AIæœåŠ¡åˆå§‹åŒ–

**ä»£ç ä½ç½®**: [backend/app/services/ai_service.py](../backend/app/services/ai_service.py)

**é…ç½®ä¼˜å…ˆçº§**:
```python
1. æ•°æ®åº“ model_configs (ä¼˜å…ˆçº§æœ€é«˜)
   â†“
2. ç¯å¢ƒå˜é‡ .env (å›é€€æ–¹æ¡ˆ)
```

**åˆå§‹åŒ–æµç¨‹**:
```python
from langchain_openai import init_chat_model

class AIService:
    def __init__(self, model_config_id: Optional[int] = None):
        # 1. è·å–æ¨¡å‹é…ç½®
        if model_config_id:
            config = db.query(ModelConfig).filter_by(id=model_config_id).first()
        else:
            config = db.query(ModelConfig).filter_by(is_default=True).first()

        if config:
            # ä½¿ç”¨æ•°æ®åº“é…ç½®
            api_key = config.api_key
            base_url = config.api_base
            model_name = config.selected_model  # ä»å¤šæ¨¡å‹é…ç½®ä¸­é€‰æ‹©
        else:
            # å›é€€åˆ°ç¯å¢ƒå˜é‡
            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_API_BASE")
            model_name = os.getenv("MODEL_NAME", "gpt-4")

        # 2. åˆå§‹åŒ–LLM
        self.llm = init_chat_model(
            model=model_name,
            api_key=api_key,
            base_url=base_url,
            timeout=180,  # è¶…æ—¶æ—¶é—´: 180ç§’
            max_retries=3  # æœ€å¤§é‡è¯•: 3æ¬¡
        )
```

#### 3.3 æµ‹è¯•ç‚¹ç”Ÿæˆæµç¨‹

**æ ¸å¿ƒæ–¹æ³•**: `extract_test_points(requirement_id: int)`

**æ­¥éª¤è¯¦è§£**:

**Step 1: ä»Milvusæ£€ç´¢éœ€æ±‚ä¸Šä¸‹æ–‡**
```python
# æ„å»ºAIä¸Šä¸‹æ–‡ (æœ€å¤š8000å­—ç¬¦)
requirement_context = build_ai_context(requirement_id, max_length=8000)
```

**Step 2: è¯»å–Promptæ¨¡æ¿**
```python
# ä¼˜å…ˆä» system_config è¡¨è¯»å–è‡ªå®šä¹‰Prompt
prompt_config = db.query(SystemConfig).filter_by(
    config_key="TEST_POINT_PROMPT"
).first()

if prompt_config:
    system_prompt = prompt_config.config_value
else:
    # ä½¿ç”¨é»˜è®¤Prompt
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿é™©è¡Œä¸šæµ‹è¯•ä¸“å®¶ã€‚

è¯·åˆ†æä»¥ä¸‹éœ€æ±‚æ–‡æ¡£ï¼Œè¯†åˆ«æ‰€æœ‰éœ€è¦æµ‹è¯•çš„ç‚¹ã€‚

è¦æ±‚è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„æµ‹è¯•ç‚¹ï¼š
1. **åŠŸèƒ½æ€§æµ‹è¯•ç‚¹**: æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
2. **è¾¹ç•Œæ¡ä»¶æµ‹è¯•ç‚¹**: ä¸´ç•Œå€¼ã€æå€¼ã€è¾¹ç•Œåœºæ™¯
3. **å¼‚å¸¸æƒ…å†µæµ‹è¯•ç‚¹**: é”™è¯¯è¾“å…¥ã€å¼‚å¸¸æµç¨‹
4. **ä¸šåŠ¡è§„åˆ™éªŒè¯ç‚¹**: ä¿é™©è§„åˆ™ã€è®¡ç®—é€»è¾‘ã€å®¡æ ¸æµç¨‹

å¯¹æ¯ä¸ªæµ‹è¯•ç‚¹ï¼Œè¯·è¯†åˆ«æ‰€å±ä¸šåŠ¡çº¿ï¼š
- contract (å¥‘çº¦): æŠ•ä¿ã€æ ¸ä¿ã€æ‰¿ä¿
- preservation (ä¿å…¨): ä¿å•å˜æ›´ã€é€€ä¿ã€å¤æ•ˆ
- claim (ç†èµ”): æŠ¥æ¡ˆã€ç†èµ”å®¡æ ¸ã€èµ”ä»˜

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªæµ‹è¯•ç‚¹åŒ…å«ï¼š
- title: æµ‹è¯•ç‚¹æ ‡é¢˜ (ç®€æ´æ˜äº†)
- description: è¯¦ç»†æè¿° (åŒ…å«æµ‹è¯•ç›®çš„ã€è¦†ç›–åœºæ™¯)
- category: ç±»å‹ (åŠŸèƒ½/è¾¹ç•Œ/å¼‚å¸¸/ä¸šåŠ¡è§„åˆ™)
- priority: ä¼˜å…ˆçº§ (high/medium/low)
- business_line: ä¸šåŠ¡çº¿ (contract/preservation/claim)

ç¤ºä¾‹ï¼š
[
  {
    "title": "æŠ•ä¿å¹´é¾„è¾¹ç•Œå€¼æµ‹è¯•",
    "description": "æµ‹è¯•æŠ•ä¿å¹´é¾„çš„ä¸´ç•Œå€¼ï¼š18å‘¨å²ã€65å‘¨å²ï¼Œä»¥åŠè¶…å‡ºèŒƒå›´çš„æƒ…å†µ",
    "category": "è¾¹ç•Œ",
    "priority": "high",
    "business_line": "contract"
  }
]
"""
```

**Step 3: è°ƒç”¨LLMç”Ÿæˆæµ‹è¯•ç‚¹**
```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content=system_prompt),
    HumanMessage(content=f"éœ€æ±‚æ–‡æ¡£å†…å®¹ï¼š\n\n{requirement_context}")
]

response = self.llm.invoke(messages)
```

**Step 4: å¢å¼ºJSONè§£æ**
```python
def parse_json_response(response_text: str) -> List[dict]:
    """å¤šå±‚è§£æç­–ç•¥, å¢å¼ºé²æ£’æ€§"""

    # ç­–ç•¥1: ä¼˜å…ˆæå– [...] æ•°ç»„éƒ¨åˆ†
    import re
    array_match = re.search(r'\[[\s\S]*\]', response_text)
    if array_match:
        try:
            return json.loads(array_match.group())
        except:
            pass

    # ç­–ç•¥2: å°è¯•è§£æå®Œæ•´å“åº”
    try:
        return json.loads(response_text)
    except:
        pass

    # ç­–ç•¥3: æå–markdownä»£ç å—
    code_block_match = re.search(r'```json\n([\s\S]*?)\n```', response_text)
    if code_block_match:
        try:
            return json.loads(code_block_match.group(1))
        except:
            pass

    # ç­–ç•¥4: å¤±è´¥æ—¶è¿”å›ç¤ºä¾‹æ•°æ® (é¿å…å‰ç«¯å´©æºƒ)
    logger.warning(f"JSONè§£æå¤±è´¥, è¿”å›ç¤ºä¾‹æ•°æ®")
    return [
        {
            "title": "è§£æå¤±è´¥-è¯·æ‰‹åŠ¨æ£€æŸ¥",
            "description": "AIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—",
            "category": "åŠŸèƒ½",
            "priority": "medium",
            "business_line": "contract"
        }
    ]
```

**Step 5: ä¿å­˜åˆ°æ•°æ®åº“**
```python
test_points = []
for point_data in parsed_response:
    test_point = TestPoint(
        requirement_id=requirement_id,
        title=point_data['title'],
        description=point_data['description'],
        category=point_data['category'],
        priority=point_data['priority'],
        business_line=point_data.get('business_line', 'contract'),
        status='pending',  # åˆå§‹çŠ¶æ€: å¾…å®¡æ‰¹
        user_id=current_user.id
    )
    db.add(test_point)
    test_points.append(test_point)

db.commit()
```

**Step 6: WebSocketå®æ—¶æ¨é€**
```python
await websocket_manager.broadcast(
    user_id=current_user.id,
    message={
        "type": "test_points_generated",
        "requirement_id": requirement_id,
        "test_points_count": len(test_points),
        "status": "success"
    }
)
```

#### 3.4 é‡è¯•æœºåˆ¶

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),  # æœ€å¤§é‡è¯•3æ¬¡
    wait=wait_exponential(multiplier=1, min=2, max=10),  # æŒ‡æ•°é€€é¿
    reraise=True
)
def call_llm_with_retry(messages):
    return llm.invoke(messages)
```

#### 3.5 æ€§èƒ½æŒ‡æ ‡

**è®°å½•è¯¦ç»†æ—¥å¿—**:
```python
import time

start_time = time.time()
response = self.llm.invoke(messages)
elapsed_time = time.time() - start_time

logger.info(f"æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆ: requirement_id={requirement_id}, "
            f"è€—æ—¶={elapsed_time:.2f}ç§’, "
            f"æµ‹è¯•ç‚¹æ•°é‡={len(test_points)}")
```

---

### é˜¶æ®µ 4: æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ (RAGå¢å¼º)

#### 4.1 APIç«¯ç‚¹

**ç«¯ç‚¹**: `POST /api/v1/test-cases/generate`
**ä»£ç ä½ç½®**: [backend/app/api/v1/endpoints/test_cases.py](../backend/app/api/v1/endpoints/test_cases.py)

**è¯·æ±‚å‚æ•°**:
```json
{
  "test_point_ids": [1, 2, 3],  // æµ‹è¯•ç‚¹IDåˆ—è¡¨
  "model_config_id": 1           // å¯é€‰
}
```

#### 4.2 RAGæ£€ç´¢å¢å¼º

**ä»£ç ä½ç½®**: [backend/app/services/rag_service.py](../backend/app/services/rag_service.py)

**æ£€ç´¢æµç¨‹**:

**Step 1: ç”ŸæˆæŸ¥è¯¢å‘é‡**
```python
def generate_query_embedding(test_point: TestPoint) -> List[float]:
    query_text = f"{test_point.title}\n{test_point.description}"

    response = requests.post(
        f"{EMBEDDING_API_BASE}/embeddings",
        headers={"Authorization": f"Bearer {EMBEDDING_API_KEY}"},
        json={
            "model": EMBEDDING_MODEL,
            "input": [query_text]
        }
    )

    return response.json()['data'][0]['embedding']
```

**Step 2: ä»Milvusæ£€ç´¢ç›¸å…³æ–‡æ¡£**
```python
def retrieve_relevant_context(
    requirement_id: int,
    query_embedding: List[float],
    top_k: int = 5
) -> str:
    collection = Collection("requirement_knowledge")

    # å‘é‡ç›¸ä¼¼åº¦æœç´¢
    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10}
    }

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        expr=f"requirement_id == {requirement_id}",
        output_fields=["text"]
    )

    # æ‹¼æ¥æ‰€æœ‰ç›¸å…³ç‰‡æ®µ
    context_parts = []
    for i, hit in enumerate(results[0]):
        context_parts.append(f"[ç›¸å…³ç‰‡æ®µ {i+1}]\n{hit.entity.get('text')}\n")

    return "\n".join(context_parts)
```

#### 4.3 ä¸šåŠ¡çº¿æ™ºèƒ½è¯†åˆ«

**æ ¹æ®æµ‹è¯•ç‚¹çš„ `business_line` å­—æ®µé€‰æ‹©Prompt**:

```python
def get_test_case_prompt(business_line: str) -> str:
    # Prompté…ç½®é”®æ˜ å°„
    prompt_key_mapping = {
        "contract": "CONTRACT_TEST_CASE_PROMPT",        # å¥‘çº¦ä¸šåŠ¡
        "preservation": "PRESERVATION_TEST_CASE_PROMPT", # ä¿å…¨ä¸šåŠ¡
        "claim": "CLAIM_TEST_CASE_PROMPT",              # ç†èµ”ä¸šåŠ¡
    }

    prompt_key = prompt_key_mapping.get(business_line, "TEST_CASE_PROMPT")

    # ä» system_config è¡¨è¯»å–
    config = db.query(SystemConfig).filter_by(config_key=prompt_key).first()

    if config:
        return config.config_value
    else:
        # ä½¿ç”¨é»˜è®¤é€šç”¨æ¨¡æ¿
        return get_default_test_case_prompt()
```

#### 4.4 æµ‹è¯•ç”¨ä¾‹ç”ŸæˆPrompt

**é»˜è®¤Promptæ¨¡æ¿**:
```python
def get_default_test_case_prompt() -> str:
    return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿é™©è¡Œä¸šæµ‹è¯•å·¥ç¨‹å¸ˆã€‚

è¯·æ ¹æ®ä»¥ä¸‹æµ‹è¯•ç‚¹å’Œéœ€æ±‚ä¸Šä¸‹æ–‡ï¼Œè®¾è®¡è¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

æµ‹è¯•ç‚¹ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š{title}
- æè¿°ï¼š{description}
- åˆ†ç±»ï¼š{category}
- ä¼˜å…ˆçº§ï¼š{priority}

éœ€æ±‚ä¸Šä¸‹æ–‡ï¼š
{context}

è¯·ä¸ºè¯¥æµ‹è¯•ç‚¹ç”Ÿæˆ 2-3 ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–ä»¥ä¸‹åœºæ™¯ï¼š
1. **æ­£å¸¸æµç¨‹**: æ ‡å‡†ä¸šåŠ¡æµç¨‹
2. **è¾¹ç•Œæ¡ä»¶**: ä¸´ç•Œå€¼ã€æå€¼åœºæ™¯
3. **å¼‚å¸¸åœºæ™¯**: é”™è¯¯è¾“å…¥ã€å¼‚å¸¸æµç¨‹

æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹åŒ…å«ï¼š
- title: ç”¨ä¾‹æ ‡é¢˜ (æ˜ç¡®ã€å…·ä½“)
- description: ç”¨ä¾‹æè¿°
- preconditions: å‰ç½®æ¡ä»¶ (æµ‹è¯•å‰éœ€è¦æ»¡è¶³çš„æ¡ä»¶)
- test_steps: æµ‹è¯•æ­¥éª¤ (æ•°ç»„æ ¼å¼)
  - step: æ­¥éª¤åºå·
  - action: æ“ä½œæè¿°
  - expected: é¢„æœŸç»“æœ
- expected_result: æ€»ä½“é¢„æœŸç»“æœ
- priority: ä¼˜å…ˆçº§ (high/medium/low)
- test_type: æµ‹è¯•ç±»å‹ (functional/boundary/exception)

è¾“å‡ºJSONæ ¼å¼ï¼š
[
  {
    "title": "æ­£å¸¸æŠ•ä¿æµç¨‹-æœˆç¼´",
    "description": "éªŒè¯æ­£å¸¸æŠ•ä¿æµç¨‹ï¼Œé€‰æ‹©æœˆç¼´æ–¹å¼",
    "preconditions": "1. ç”¨æˆ·å·²ç™»å½•ï¼›2. äº§å“å¯æŠ•ä¿",
    "test_steps": [
      {
        "step": 1,
        "action": "è¿›å…¥äº§å“æŠ•ä¿é¡µé¢",
        "expected": "é¡µé¢æ­£å¸¸å±•ç¤ºäº§å“ä¿¡æ¯"
      },
      {
        "step": 2,
        "action": "å¡«å†™æŠ•ä¿äººä¿¡æ¯ï¼šå§“åã€èº«ä»½è¯ã€å¹´é¾„30å²",
        "expected": "ä¿¡æ¯å¡«å†™æˆåŠŸ"
      },
      {
        "step": 3,
        "action": "é€‰æ‹©ç¼´è´¹æ–¹å¼ï¼šæœˆç¼´",
        "expected": "æœˆç¼´æ–¹å¼é€‰ä¸­ï¼Œæ˜¾ç¤ºå¯¹åº”ä¿è´¹"
      },
      {
        "step": 4,
        "action": "æäº¤æŠ•ä¿ç”³è¯·",
        "expected": "æŠ•ä¿æˆåŠŸï¼Œç”Ÿæˆä¿å•å·"
      }
    ],
    "expected_result": "æŠ•ä¿æµç¨‹æ­£å¸¸å®Œæˆï¼Œä¿å•çŠ¶æ€ä¸ºå¾…æ ¸ä¿",
    "priority": "high",
    "test_type": "functional"
  }
]
"""
```

#### 4.5 è°ƒç”¨LLMç”Ÿæˆç”¨ä¾‹

```python
def generate_test_cases(test_point_id: int) -> List[TestCase]:
    # 1. è·å–æµ‹è¯•ç‚¹
    test_point = db.query(TestPoint).filter_by(id=test_point_id).first()

    # 2. RAGæ£€ç´¢ç›¸å…³éœ€æ±‚ä¸Šä¸‹æ–‡
    query_embedding = generate_query_embedding(test_point)
    context = retrieve_relevant_context(
        test_point.requirement_id,
        query_embedding,
        top_k=5
    )

    # 3. è·å–Promptæ¨¡æ¿
    system_prompt = get_test_case_prompt(test_point.business_line)

    # 4. æ„å»ºæ¶ˆæ¯
    user_message = system_prompt.format(
        title=test_point.title,
        description=test_point.description,
        category=test_point.category,
        priority=test_point.priority,
        context=context
    )

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆ"),
        HumanMessage(content=user_message)
    ]

    # 5. è°ƒç”¨LLM
    response = self.llm.invoke(messages)

    # 6. è§£æJSONå“åº”
    test_cases_data = parse_json_response(response.content)

    # 7. ä¿å­˜åˆ°æ•°æ®åº“
    test_cases = []
    for case_data in test_cases_data:
        test_case = TestCase(
            test_point_id=test_point_id,
            requirement_id=test_point.requirement_id,
            title=case_data['title'],
            description=case_data['description'],
            preconditions=case_data['preconditions'],
            test_steps=json.dumps(case_data['test_steps'], ensure_ascii=False),
            expected_result=case_data['expected_result'],
            priority=case_data['priority'],
            test_type=case_data['test_type'],
            status='pending',
            user_id=current_user.id
        )
        db.add(test_case)
        test_cases.append(test_case)

    db.commit()

    # 8. WebSocketé€šçŸ¥
    await websocket_manager.broadcast(
        user_id=current_user.id,
        message={
            "type": "test_case_generated",
            "test_point_id": test_point_id,
            "test_cases_count": len(test_cases)
        }
    )

    return test_cases
```

#### 4.6 ç”Ÿæˆç­–ç•¥

**æ¯ä¸ªæµ‹è¯•ç‚¹ç”Ÿæˆ 2-3 ä¸ªæµ‹è¯•ç”¨ä¾‹**:
- âœ… æ­£å¸¸æµç¨‹ç”¨ä¾‹ (åŠŸèƒ½æ€§)
- âœ… è¾¹ç•Œæ¡ä»¶ç”¨ä¾‹ (è¾¹ç•Œå€¼)
- âœ… å¼‚å¸¸åœºæ™¯ç”¨ä¾‹ (å¼‚å¸¸å¤„ç†)

---

### é˜¶æ®µ 5: è‡ªåŠ¨åŒ–å¹³å°é›†æˆ (å…³é”®æµç¨‹)

#### 5.1 å¤„ç†æœåŠ¡

**ä»£ç ä½ç½®**: [backend/app/services/automation_service.py](../backend/app/services/automation_service.py)
**APIç«¯ç‚¹**: [backend/app/api/v1/endpoints/automation_workflow.py](../backend/app/api/v1/endpoints/automation_workflow.py)

#### 5.2 æ ¸å¿ƒæ–¹æ³•

**æ–¹æ³•ç­¾å**:
```python
def create_case_with_fields(
    scene_id: int,
    test_case_info: dict
) -> dict:
    """
    è‡ªåŠ¨åŒ–å¹³å°é›†æˆ: åˆ›å»ºç”¨ä¾‹å’Œæ˜ç»†

    Args:
        scene_id: è‡ªåŠ¨åŒ–å¹³å°åœºæ™¯ID
        test_case_info: æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯
            {
                "title": "ç”¨ä¾‹æ ‡é¢˜",
                "description": "ç”¨ä¾‹æè¿°",
                "test_steps": [...],
                "expected_result": "é¢„æœŸç»“æœ"
            }

    Returns:
        {
            "success": True/False,
            "case_id": "åˆ›å»ºçš„ç”¨ä¾‹ID",
            "message": "å¤„ç†æ¶ˆæ¯"
        }
    """
```

#### 5.3 è¯¦ç»†æµç¨‹

##### **Step 1: è·å–åœºæ™¯ç”¨ä¾‹åˆ—è¡¨**

```python
def get_scene_cases(scene_id: int) -> List[dict]:
    """ä»è‡ªåŠ¨åŒ–å¹³å°è·å–åœºæ™¯ä¸‹æ‰€æœ‰å¯ç”¨ç”¨ä¾‹æ¨¡æ¿"""

    url = f"{AUTOMATION_PLATFORM_API_BASE}/ai/case/queryBySceneId/{scene_id}"

    response = requests.get(url, timeout=30)
    response.raise_for_status()

    data = response.json()

    if data['code'] == 200:
        return data['data']  # ç”¨ä¾‹åˆ—è¡¨
    else:
        raise Exception(f"è·å–åœºæ™¯ç”¨ä¾‹å¤±è´¥: {data['message']}")
```

**è¿”å›æ•°æ®ç¤ºä¾‹**:
```json
[
  {
    "usercaseId": 1001,
    "name": "äººå¯¿ä¿é™©æŠ•ä¿ç”¨ä¾‹",
    "description": "ç”¨äºæµ‹è¯•äººå¯¿ä¿é™©æŠ•ä¿æµç¨‹ï¼ŒåŒ…å«æŠ•ä¿äººä¿¡æ¯ã€è¢«ä¿é™©äººä¿¡æ¯ã€ç¼´è´¹æ–¹å¼ç­‰",
    "sceneId": 100
  },
  {
    "usercaseId": 1002,
    "name": "æ„å¤–é™©æŠ•ä¿ç”¨ä¾‹",
    "description": "ç”¨äºæµ‹è¯•æ„å¤–é™©æŠ•ä¿æµç¨‹...",
    "sceneId": 100
  }
]
```

##### **Step 2: AIé€‰æ‹©æœ€åŒ¹é…ç”¨ä¾‹ (180ç§’è¶…æ—¶ä¿æŠ¤)**

**è¶…æ—¶ä¿æŠ¤æœºåˆ¶**:
```python
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError
import logging

def select_best_case_by_ai(
    test_case_info: dict,
    available_cases: List[dict]
) -> dict:
    """AIé€‰æ‹©æœ€åŒ¹é…çš„ç”¨ä¾‹æ¨¡æ¿"""

    # ä¼˜åŒ–: å¦‚æœåªæœ‰1ä¸ªç”¨ä¾‹ï¼Œç›´æ¥è¿”å›
    if len(available_cases) == 1:
        logger.info("åªæœ‰1ä¸ªå¯ç”¨ç”¨ä¾‹ï¼Œè·³è¿‡AIé€‰æ‹©")
        return available_cases[0]

    # ä¼˜åŒ–Prompt: å‡å°‘çº¦70% Tokenä½¿ç”¨
    cases_for_ai = [
        {
            'id': str(c.get('usercaseId')),
            'name': str(c.get('name')),
            'desc': str(c.get('description', ''))[:150]  # æˆªæ–­æè¿°
        }
        for c in available_cases
    ]

    test_title = test_case_info.get('title', '')[:100]
    test_desc = test_case_info.get('description', '')[:200]

    prompt = f"""è¯·ä»ä»¥ä¸‹ç”¨ä¾‹æ¨¡æ¿ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªï¼š

æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{test_title}
æè¿°ï¼š{test_desc}

å¯ç”¨æ¨¡æ¿ï¼š
{json.dumps(cases_for_ai, ensure_ascii=False)}

è¯·è¿”å›æœ€åŒ¹é…æ¨¡æ¿çš„IDï¼ˆåªè¿”å›æ•°å­—ï¼‰ã€‚
"""

    # ä½¿ç”¨çº¿ç¨‹æ±  + è¶…æ—¶ä¿æŠ¤
    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(call_ai_to_select, prompt)

        try:
            # 180ç§’è¶…æ—¶
            selected_id = future.result(timeout=180)

            # æŸ¥æ‰¾å¯¹åº”ç”¨ä¾‹
            for case in available_cases:
                if str(case['usercaseId']) == str(selected_id):
                    logger.info(f"AIé€‰æ‹©ç”¨ä¾‹æˆåŠŸ: {case['name']}")
                    return case

            # æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
            logger.warning(f"AIè¿”å›çš„ID {selected_id} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨ä¾‹")
            return available_cases[0]

        except FutureTimeoutError:
            # è¶…æ—¶é™çº§ç­–ç•¥
            logger.warning("AIé€‰æ‹©ç”¨ä¾‹è¶…æ—¶ï¼ˆ180ç§’ï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨ç”¨ä¾‹")
            return available_cases[0]

        except Exception as e:
            # å…¶ä»–å¼‚å¸¸é™çº§
            logger.error(f"AIé€‰æ‹©ç”¨ä¾‹å¤±è´¥: {e}ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨ç”¨ä¾‹")
            return available_cases[0]


def call_ai_to_select(prompt: str) -> str:
    """è°ƒç”¨AIé€‰æ‹©ç”¨ä¾‹"""
    messages = [
        SystemMessage(content="ä½ æ˜¯ç”¨ä¾‹é€‰æ‹©ä¸“å®¶ï¼Œåªè¿”å›æœ€åŒ¹é…çš„ç”¨ä¾‹IDæ•°å­—"),
        HumanMessage(content=prompt)
    ]

    response = llm.invoke(messages)

    # æå–æ•°å­—ID
    import re
    match = re.search(r'\d+', response.content)
    if match:
        return match.group()
    else:
        raise ValueError("AIæœªè¿”å›æœ‰æ•ˆID")
```

##### **Step 3: è·å–ç”¨ä¾‹è¯¦æƒ…**

```python
def get_case_detail(usercase_id: int) -> dict:
    """è·å–ç”¨ä¾‹è¯¦æƒ…ï¼ˆå«headerå’Œbodyæ¨¡æ¿ï¼‰"""

    url = f"{AUTOMATION_PLATFORM_API_BASE}/ai/case/queryCaseBody/{usercase_id}"

    response = requests.get(url, timeout=30)
    response.raise_for_status()

    data = response.json()

    if data['code'] == 200:
        return data['data']  # åŒ…å« caseDefine ç»“æ„
    else:
        raise Exception(f"è·å–ç”¨ä¾‹è¯¦æƒ…å¤±è´¥: {data['message']}")
```

**è¿”å›æ•°æ®ç»“æ„ (caseDefine)**:
```json
{
  "usercaseId": 1001,
  "name": "äººå¯¿ä¿é™©æŠ•ä¿ç”¨ä¾‹",
  "caseDefine": {
    "header": [
      {
        "rowName": "æŠ•ä¿äººå§“å",
        "row": "applicantName",
        "type": "String",
        "flag": "input"
      },
      {
        "rowName": "æŠ•ä¿äººå¹´é¾„",
        "row": "applicantAge",
        "type": "Integer",
        "flag": "input"
      },
      {
        "rowName": "ç¼´è´¹æ–¹å¼",
        "row": "paymentMode",
        "type": "String",
        "flag": "select",
        "options": ["æœˆç¼´", "å­£ç¼´", "å¹´ç¼´"]
      }
    ],
    "body": [
      {
        "casedesc": "æ­£å¸¸æŠ•ä¿-æœˆç¼´",
        "casezf": "1",
        "hoperesult": "æŠ•ä¿æˆåŠŸ",
        "var": {
          "applicantName": "å¼ ä¸‰",
          "applicantAge": 30,
          "paymentMode": "æœˆç¼´"
        },
        "iscaserun": true,
        "caseBodySN": 1
      }
    ]
  }
}
```

##### **Step 4: AIç”Ÿæˆæµ‹è¯•æ•°æ® (Body)**

**å¢å¼ºç‰ˆç”Ÿæˆï¼ˆV2ï¼‰**:
```python
def generate_case_body_by_ai(
    header_fields: List[dict],
    test_case_info: dict
) -> List[dict]:
    """AIç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆbodyï¼‰"""

    # æå–å­—æ®µä¿¡æ¯
    fields_info = []
    for field in header_fields:
        field_desc = f"- {field['rowName']} ({field['row']}): ç±»å‹={field['type']}"

        # æ·»åŠ æšä¸¾å€¼çº¦æŸ
        if 'options' in field:
            field_desc += f", å¯é€‰å€¼={field['options']}"

        # æ·»åŠ å¿…å¡«æ ‡è¯†
        if field.get('required'):
            field_desc += ", å¿…å¡«"

        fields_info.append(field_desc)

    # æ„å»ºPrompt
    prompt = f"""è¯·æ ¹æ®æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯å’Œå­—æ®µå®šä¹‰ï¼Œç”ŸæˆçœŸå®ã€åˆç†çš„æµ‹è¯•æ•°æ®ã€‚

æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{test_case_info['title']}
æè¿°ï¼š{test_case_info['description']}
æµ‹è¯•æ­¥éª¤ï¼š
{json.dumps(test_case_info.get('test_steps', []), ensure_ascii=False, indent=2)}

å­—æ®µå®šä¹‰ï¼š
{chr(10).join(fields_info)}

è¦æ±‚ï¼š
1. æ ¹æ®æµ‹è¯•ç”¨ä¾‹å…·ä½“å†…å®¹ç”Ÿæˆæ•°æ®
2. æ•°æ®çœŸå®ã€åˆç†ã€ç¬¦åˆä¸šåŠ¡é€»è¾‘
3. ç”Ÿæˆ1-3æ¡æµ‹è¯•æ•°æ®ï¼Œè¦†ç›–ä¸åŒåœºæ™¯
4. å­—æ®µå€¼ç¬¦åˆç±»å‹å’Œä¸šåŠ¡å«ä¹‰
5. æ—¥æœŸä½¿ç”¨YYYYMMDDæ ¼å¼ï¼ˆä½¿ç”¨current_date_yyyymmdd_toolå·¥å…·è·å–å½“å‰æ—¥æœŸï¼‰
6. éµå®ˆå­—æ®µè”åŠ¨è§„åˆ™ï¼ˆå¦‚æœ‰ï¼‰

è¾“å‡ºJSONæ ¼å¼ï¼š
[
  {{
    "casedesc": "æµ‹è¯•è§’åº¦/åœºæ™¯æè¿°ï¼ˆå¦‚'æ­£å¸¸æŠ•ä¿-æœˆç¼´'ã€'å¹´é¾„è¾¹ç•Œå€¼æµ‹è¯•'ï¼‰",
    "casezf": "1",  // 1=æ­£å‘ç”¨ä¾‹, 0=åå‘ç”¨ä¾‹
    "hoperesult": "é¢„æœŸç»“æœ",
    "var": {{
      "å­—æ®µå1": "å€¼1",
      "å­—æ®µå2": "å€¼2"
    }},
    "iscaserun": true,
    "caseBodySN": 1
  }}
]
"""

    # ç»‘å®šå·¥å…·ï¼ˆæ—¥æœŸ/æ—¶é—´ï¼‰
    tools = [
        current_date_tool,
        current_datetime_tool,
        current_date_yyyymmdd_tool
    ]

    llm_with_tools = llm.bind_tools(tools)

    messages = [
        SystemMessage(content="ä½ æ˜¯æµ‹è¯•æ•°æ®ç”Ÿæˆä¸“å®¶"),
        HumanMessage(content=prompt)
    ]

    # è°ƒç”¨LLM
    response = llm_with_tools.invoke(messages)

    # å¢å¼ºJSONè§£æ
    body_data = parse_agent_response(response.content)

    return body_data
```

**Agentå·¥å…·å®šä¹‰**:
```python
from langchain.tools import tool
from datetime import datetime

@tool
def current_date_yyyymmdd_tool() -> str:
    """è·å–å½“å‰æ—¥æœŸï¼ŒYYYYMMDDæ ¼å¼"""
    return datetime.now().strftime("%Y%m%d")

@tool
def current_date_tool() -> str:
    """è·å–å½“å‰æ—¥æœŸï¼ŒYYYY-MM-DDæ ¼å¼"""
    return datetime.now().strftime("%Y-%m-%d")

@tool
def current_datetime_tool() -> str:
    """è·å–å½“å‰æ—¥æœŸæ—¶é—´ï¼ŒYYYY-MM-DD HH:MM:SSæ ¼å¼"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
```

**å¢å¼ºJSONè§£æ**:
```python
def parse_agent_response(response_text: str) -> List[dict]:
    """å¤šå±‚è§£æç­–ç•¥ï¼Œå¤„ç†Agentç»“æ„åŒ–å“åº”"""

    # ç­–ç•¥1: æå– detail='[...]' (Agentç»“æ„åŒ–å“åº”)
    import re
    detail_match = re.search(r"detail='(\[[\s\S]*?\])'", response_text)
    if detail_match:
        try:
            json_str = detail_match.group(1)
            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            json_str = json_str.replace('\\n', '\n')
            return json.loads(json_str)
        except:
            pass

    # ç­–ç•¥2: æå– answer='...'
    answer_match = re.search(r"answer='([\s\S]*?)'", response_text)
    if answer_match:
        try:
            json_str = answer_match.group(1)
            return json.loads(json_str)
        except:
            pass

    # ç­–ç•¥3: æå– markdownä»£ç å— ```json...```
    code_block_match = re.search(r'```json\n([\s\S]*?)\n```', response_text)
    if code_block_match:
        try:
            return json.loads(code_block_match.group(1))
        except:
            pass

    # ç­–ç•¥4: ç›´æ¥è§£ææ•´ä½“
    try:
        return json.loads(response_text)
    except:
        pass

    # ç­–ç•¥5: å½’ä¸€åŒ–å¤„ç† \n è½¬ä¹‰
    try:
        normalized = response_text.replace('\\n', '\n')
        return json.loads(normalized)
    except:
        pass

    # ç­–ç•¥6: å…œåº•æå– [...] æˆ– {...} ç‰‡æ®µ
    array_match = re.search(r'\[[\s\S]*\]', response_text)
    if array_match:
        try:
            return json.loads(array_match.group())
        except:
            pass

    # å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    raise ValueError(f"æ— æ³•è§£æAIå“åº”ä¸ºJSON: {response_text[:200]}")
```

##### **Step 5: åˆ›å»ºç”¨ä¾‹å’Œæ˜ç»†**

```python
def create_case_and_body(
    usercase_id: int,
    case_define: dict
) -> dict:
    """è°ƒç”¨è‡ªåŠ¨åŒ–å¹³å°APIåˆ›å»ºç”¨ä¾‹"""

    url = f"{AUTOMATION_PLATFORM_API_BASE}/ai/case/createCaseAndBody"

    payload = {
        "usercaseId": usercase_id,
        "caseDefine": case_define
    }

    response = requests.post(
        url,
        json=payload,
        headers={"Content-Type": "application/json"},
        timeout=30
    )

    response.raise_for_status()

    data = response.json()

    if data['code'] == 200:
        logger.info(f"åˆ›å»ºç”¨ä¾‹æˆåŠŸ: case_id={data['data']['caseId']}")
        return {
            "success": True,
            "case_id": data['data']['caseId'],
            "message": "åˆ›å»ºæˆåŠŸ"
        }
    else:
        logger.error(f"åˆ›å»ºç”¨ä¾‹å¤±è´¥: {data['message']}")
        return {
            "success": False,
            "message": data['message']
        }
```

#### 5.4 å®Œæ•´æµç¨‹ä»£ç 

```python
def create_case_with_fields(
    scene_id: int,
    test_case_info: dict
) -> dict:
    """å®Œæ•´æµç¨‹: ä»æµ‹è¯•ç”¨ä¾‹åˆ°è‡ªåŠ¨åŒ–å¹³å°ç”¨ä¾‹"""

    try:
        # Step 1: è·å–åœºæ™¯ç”¨ä¾‹åˆ—è¡¨
        logger.info(f"Step 1: è·å–åœºæ™¯ {scene_id} çš„ç”¨ä¾‹åˆ—è¡¨")
        available_cases = get_scene_cases(scene_id)

        if not available_cases:
            return {"success": False, "message": "è¯¥åœºæ™¯ä¸‹æ²¡æœ‰å¯ç”¨ç”¨ä¾‹"}

        # Step 2: AIé€‰æ‹©æœ€åŒ¹é…ç”¨ä¾‹ï¼ˆ180ç§’è¶…æ—¶ä¿æŠ¤ï¼‰
        logger.info(f"Step 2: AIé€‰æ‹©æœ€åŒ¹é…ç”¨ä¾‹ï¼ˆå…± {len(available_cases)} ä¸ªå¯é€‰ï¼‰")
        selected_case = select_best_case_by_ai(test_case_info, available_cases)

        # Step 3: è·å–ç”¨ä¾‹è¯¦æƒ…
        logger.info(f"Step 3: è·å–ç”¨ä¾‹è¯¦æƒ… (usercaseId={selected_case['usercaseId']})")
        case_detail = get_case_detail(selected_case['usercaseId'])

        header_fields = case_detail['caseDefine']['header']

        # Step 4: AIç”Ÿæˆæµ‹è¯•æ•°æ®
        logger.info(f"Step 4: AIç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆå…± {len(header_fields)} ä¸ªå­—æ®µï¼‰")
        generated_body = generate_case_body_by_ai(header_fields, test_case_info)

        # Step 5: åˆ›å»ºç”¨ä¾‹å’Œæ˜ç»†
        logger.info(f"Step 5: åˆ›å»ºç”¨ä¾‹å’Œæ˜ç»†ï¼ˆå…± {len(generated_body)} æ¡æ•°æ®ï¼‰")
        new_case_define = {
            "header": header_fields,
            "body": generated_body
        }

        result = create_case_and_body(
            selected_case['usercaseId'],
            new_case_define
        )

        return result

    except Exception as e:
        logger.error(f"åˆ›å»ºç”¨ä¾‹å¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "message": f"åˆ›å»ºå¤±è´¥: {str(e)}"
        }
```

#### 5.5 è‡ªåŠ¨åŒ–å¹³å°APIé›†æˆ

**åŸºç¡€é…ç½®**:
```python
# ä» system_config è¡¨æˆ–ç¯å¢ƒå˜é‡è¯»å–
AUTOMATION_PLATFORM_API_BASE = get_config_value(
    "AUTOMATION_PLATFORM_API_BASE",
    default=os.getenv("AUTOMATION_PLATFORM_API_BASE")
)
```

**å…³é”®APIç«¯ç‚¹**:

| æ–¹æ³• | ç«¯ç‚¹ | è¯´æ˜ |
|------|------|------|
| GET | `/ai/case/queryBySceneId/{sceneId}` | è·å–åœºæ™¯ç”¨ä¾‹åˆ—è¡¨ |
| GET | `/ai/case/queryCaseBody/{id}` | è·å–ç”¨ä¾‹è¯¦æƒ… |
| POST | `/ai/case/createCaseAndBody` | åˆ›å»ºç”¨ä¾‹å’Œæ˜ç»† |
| GET | `/ai/case/queryAllScenes` | è·å–æ‰€æœ‰åœºæ™¯ |

**é”™è¯¯å¤„ç†**:
```python
# è¿æ¥è¶…æ—¶: 30ç§’
# HTTPçŠ¶æ€æ£€æŸ¥
# JSONè§£æéªŒè¯
# è¯¦ç»†æ—¥å¿—è®°å½•
```

---

## ğŸ”§ å…³é”®æŠ€æœ¯ç‰¹æ€§

### 1. å¤šæ¨¡å‹é…ç½®æ”¯æŒ

**æ•°æ®åº“ç»“æ„** (`model_configs` è¡¨):
```sql
CREATE TABLE model_configs (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    api_key TEXT NOT NULL,
    api_base TEXT NOT NULL,
    model_name JSONB NOT NULL,  -- JSONæ•°ç»„: ["gpt-4", "gpt-3.5-turbo"]
    selected_model VARCHAR(100) NOT NULL,  -- å½“å‰ä½¿ç”¨çš„æ¨¡å‹
    temperature DECIMAL(3,2),
    is_default BOOLEAN DEFAULT FALSE,
    user_id INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);
```

**é…ç½®ä¼˜å…ˆçº§**:
```
æ•°æ®åº“ model_configs (ä¼˜å…ˆçº§æœ€é«˜)
    â†“
ç¯å¢ƒå˜é‡ .env (å›é€€æ–¹æ¡ˆ)
```

### 2. é…ç½®åŒ–Prompt

**æ‰€æœ‰Promptå¯ä» `system_config` è¡¨åŠ¨æ€è¯»å–**:

| é…ç½®é”® | è¯´æ˜ |
|--------|------|
| `TEST_POINT_PROMPT` | æµ‹è¯•ç‚¹ç”ŸæˆPrompt |
| `CONTRACT_TEST_CASE_PROMPT` | å¥‘çº¦ä¸šåŠ¡ç”¨ä¾‹Prompt |
| `PRESERVATION_TEST_CASE_PROMPT` | ä¿å…¨ä¸šåŠ¡ç”¨ä¾‹Prompt |
| `CLAIM_TEST_CASE_PROMPT` | ç†èµ”ä¸šåŠ¡ç”¨ä¾‹Prompt |
| `TEST_CASE_PROMPT` | é»˜è®¤é€šç”¨ç”¨ä¾‹Prompt |

**åŠ¨æ€è¯»å–ç¤ºä¾‹**:
```python
def get_prompt_from_config(prompt_key: str, default: str) -> str:
    config = db.query(SystemConfig).filter_by(config_key=prompt_key).first()
    return config.config_value if config else default
```

### 3. Agentå·¥å…·è°ƒç”¨

**å†…ç½®å·¥å…·**:
```python
# æ—¥æœŸ/æ—¶é—´å·¥å…·
- current_date_tool: è·å–å½“å‰æ—¥æœŸ (YYYY-MM-DD)
- current_datetime_tool: è·å–å½“å‰æ—¥æœŸæ—¶é—´ (YYYY-MM-DD HH:MM:SS)
- current_date_yyyymmdd_tool: è·å–YYYYMMDDæ ¼å¼æ—¥æœŸ
```

**å·¥å…·ç»‘å®š**:
```python
from langchain.tools import tool

tools = [current_date_tool, current_datetime_tool, current_date_yyyymmdd_tool]
llm_with_tools = llm.bind_tools(tools)

response = llm_with_tools.invoke(messages)
```

### 4. WebSocketå®æ—¶æ¨é€

**è¿æ¥æ ¼å¼**:
```
ws://localhost:8000/api/v1/ws/{client_id}?token={jwt_token}
```

**æ¶ˆæ¯ç±»å‹**:

| ç±»å‹ | è¯´æ˜ | æ•°æ®ç»“æ„ |
|------|------|----------|
| `knowledge_base_completed` | çŸ¥è¯†åº“æ„å»ºå®Œæˆ | `{requirement_id, chunks_count, status}` |
| `test_points_generated` | æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆ | `{requirement_id, test_points_count, status}` |
| `test_case_generated` | æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ | `{test_point_id, test_cases_count}` |

**å‰ç«¯å®ç°** ([frontend/src/stores/websocketStore.ts](../frontend/src/stores/websocketStore.ts)):
```typescript
import { create } from 'zustand';

interface WebSocketStore {
  ws: WebSocket | null;
  isConnected: boolean;
  connect: (clientId: string, token: string) => void;
  disconnect: () => void;
}

export const useWebSocketStore = create<WebSocketStore>((set, get) => ({
  ws: null,
  isConnected: false,

  connect: (clientId: string, token: string) => {
    const ws = new WebSocket(
      `ws://localhost:8000/api/v1/ws/${clientId}?token=${token}`
    );

    ws.onopen = () => {
      console.log('WebSocketè¿æ¥æˆåŠŸ');
      set({ isConnected: true });
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);
      console.log('æ”¶åˆ°æ¶ˆæ¯:', message);

      // å¤„ç†ä¸åŒæ¶ˆæ¯ç±»å‹
      switch (message.type) {
        case 'test_points_generated':
          // åˆ·æ–°æµ‹è¯•ç‚¹åˆ—è¡¨
          break;
        case 'test_case_generated':
          // åˆ·æ–°æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocketé”™è¯¯:', error);
    };

    ws.onclose = () => {
      console.log('WebSocketè¿æ¥å…³é—­');
      set({ isConnected: false });

      // è‡ªåŠ¨é‡è¿æœºåˆ¶
      setTimeout(() => get().connect(clientId, token), 3000);
    };

    set({ ws });
  },

  disconnect: () => {
    const { ws } = get();
    if (ws) {
      ws.close();
      set({ ws: null, isConnected: false });
    }
  }
}));
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–æªæ–½

### 1. æ‰¹é‡å‘é‡åŒ–

**åŠ¨æ€è°ƒæ•´batch_size**:
```python
batch_size = 100  # åˆå§‹æ‰¹é‡å¤§å°

while texts_to_process:
    try:
        # æ‰¹é‡å‘é‡åŒ–
        embeddings = generate_embeddings(texts[:batch_size])

    except RequestEntityTooLarge:  # HTTP 413
        # åŠ¨æ€é™ä½æ‰¹é‡å¤§å°
        batch_size = batch_size // 2
        logger.warning(f"æ‰¹é‡å¤§å°è¿‡å¤§ï¼Œè°ƒæ•´ä¸º {batch_size}")
```

### 2. Milvuså‘é‡æ£€ç´¢ä¼˜åŒ–

**ç´¢å¼•é…ç½®**:
```python
# IVF_FLATç´¢å¼•: é«˜å¬å›ç‡
index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {"nlist": 128}
}

# æœç´¢å‚æ•°
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 10}  # æ£€ç´¢çš„èšç±»æ•°é‡
}
```

### 3. AIè°ƒç”¨è¶…æ—¶ä¿æŠ¤

**180ç§’è¶…æ—¶ + é™çº§ç­–ç•¥**:
```python
from concurrent.futures import ThreadPoolExecutor, TimeoutError

with ThreadPoolExecutor(max_workers=1) as executor:
    future = executor.submit(call_ai)

    try:
        result = future.result(timeout=180)
    except TimeoutError:
        # é™çº§: ä½¿ç”¨é»˜è®¤å€¼
        result = get_default_value()
```

### 4. Promptä¼˜åŒ–

**å‡å°‘çº¦70% Tokenä½¿ç”¨**:
```python
# ä¼˜åŒ–å‰: å®Œæ•´æè¿°
case = {
    'id': 1001,
    'name': "äººå¯¿ä¿é™©æŠ•ä¿ç”¨ä¾‹",
    'description': "ç”¨äºæµ‹è¯•äººå¯¿ä¿é™©æŠ•ä¿æµç¨‹ï¼ŒåŒ…å«æŠ•ä¿äººä¿¡æ¯ã€è¢«ä¿é™©äººä¿¡æ¯ã€ç¼´è´¹æ–¹å¼ã€ä¿é™©é‡‘é¢ã€ä¿é™©æœŸé—´ç­‰å¤šä¸ªå­—æ®µçš„éªŒè¯ï¼Œæ”¯æŒæœˆç¼´ã€å­£ç¼´ã€å¹´ç¼´å¤šç§ç¼´è´¹æ–¹å¼..."  # 300+å­—ç¬¦
}

# ä¼˜åŒ–å: æˆªæ–­æè¿°
case = {
    'id': 1001,
    'name': "äººå¯¿ä¿é™©æŠ•ä¿ç”¨ä¾‹",
    'desc': "ç”¨äºæµ‹è¯•äººå¯¿ä¿é™©æŠ•ä¿æµç¨‹ï¼ŒåŒ…å«æŠ•ä¿äººä¿¡æ¯ã€è¢«ä¿é™©äººä¿¡æ¯ã€ç¼´è´¹æ–¹å¼..."[:150]  # 150å­—ç¬¦
}
```

### 5. å¼‚æ­¥å¤„ç†

**ä½¿ç”¨ ThreadPoolExecutor é¿å…é˜»å¡**:
```python
from concurrent.futures import ThreadPoolExecutor

# å¹¶å‘å¤„ç†å¤šä¸ªæµ‹è¯•ç‚¹
with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [
        executor.submit(generate_test_cases, test_point_id)
        for test_point_id in test_point_ids
    ]

    results = [future.result() for future in futures]
```

### 6. é”™è¯¯é‡è¯•

**æœ€å¤§3æ¬¡é‡è¯• + æŒ‡æ•°é€€é¿**:
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_llm_with_retry(messages):
    return llm.invoke(messages)
```

---

## ğŸ›¡ï¸ å®¹é”™æœºåˆ¶

### 1. æ–‡æ¡£è§£æå®¹é”™

**ä¸‰å±‚å›é€€ç­–ç•¥**:
```
LangChainå·¥å…·è§£æ
    â†“ å¤±è´¥
LangChain Unstructuredè§£æ
    â†“ å¤±è´¥
åŸç”ŸPythonåº“è§£æ
```

### 2. AIè°ƒç”¨å¤±è´¥å®¹é”™

**è¿”å›ç¤ºä¾‹æ•°æ®ï¼Œé¿å…å‰ç«¯å´©æºƒ**:
```python
try:
    response = llm.invoke(messages)
    data = parse_json_response(response.content)
except Exception as e:
    logger.error(f"AIè°ƒç”¨å¤±è´¥: {e}")
    # è¿”å›ç¤ºä¾‹æ•°æ®
    data = [
        {
            "title": "AIç”Ÿæˆå¤±è´¥-ç¤ºä¾‹æµ‹è¯•ç‚¹",
            "description": "è¯·æ‰‹åŠ¨ç¼–è¾‘",
            "category": "åŠŸèƒ½",
            "priority": "medium"
        }
    ]
```

### 3. å‘é‡åŒ–å¤±è´¥å®¹é”™

**è®°å½•è­¦å‘Šï¼Œç»§ç»­åç»­æµç¨‹**:
```python
try:
    embeddings = generate_embeddings(texts)
    milvus_service.insert(embeddings)
except Exception as e:
    logger.warning(f"å‘é‡åŒ–å¤±è´¥: {e}")
    # ä¸å½±å“åç»­æµç¨‹ï¼Œä»…è®°å½•è­¦å‘Š
```

### 4. JSONè§£æå®¹é”™

**å¤šç§æå–ç­–ç•¥**:
```python
# 1. æå– [...] æ•°ç»„
# 2. æå– markdownä»£ç å—
# 3. æå– detail='...'
# 4. ç›´æ¥è§£æ
# 5. å½’ä¸€åŒ–å¤„ç†
# 6. å…œåº•æå–
```

### 5. è¶…æ—¶é™çº§

**AIè¶…æ—¶è‡ªåŠ¨ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨é€‰é¡¹**:
```python
try:
    selected = select_best_case_by_ai(test_case, cases)
except TimeoutError:
    # é™çº§: ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨ä¾‹
    selected = cases[0]
```

---

## ğŸ“Š æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  éœ€æ±‚æ–‡æ¡£ä¸Šä¼      â”‚
â”‚  (DOCX/PDF/TXT)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ–‡æ¡£è§£æ        â”‚
â”‚ (DocumentParser) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ–‡æœ¬åˆ‡åˆ†        â”‚       â”‚  ç¡…åŸºæµåŠ¨åµŒå…¥API  â”‚
â”‚ (TextSplitter)   â”‚â”€â”€â”€â”€â”€â”€>â”‚  (Embedding)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                          â”‚
         â”‚                          â–¼
         â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚   Milvuså‘é‡åº“    â”‚
         â”‚                 â”‚  (1536ç»´å‘é‡)    â”‚
         â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                          â”‚
         â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æµ‹è¯•ç‚¹ç”Ÿæˆ       â”‚<â”€â”€â”€â”€â”€â”€â”‚   RAGæ£€ç´¢        â”‚
â”‚  (AIåˆ†æ)        â”‚       â”‚  (å‘é‡ç›¸ä¼¼åº¦)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ     â”‚<â”€â”€â”€â”€â”€â”€â”‚   RAGå¢å¼º        â”‚
â”‚  (AIç”Ÿæˆ)        â”‚       â”‚  (ä¸Šä¸‹æ–‡æ£€ç´¢)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è‡ªåŠ¨åŒ–å¹³å°é›†æˆ   â”‚
â”‚  (åˆ›å»ºç”¨ä¾‹)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹   â”‚
â”‚  (å¯æ‰§è¡Œ)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ å…³é”®æ–‡ä»¶ç´¢å¼•

| é˜¶æ®µ | æ–‡ä»¶è·¯å¾„ | åŠŸèƒ½ | å…³é”®æ–¹æ³• |
|------|----------|------|----------|
| **æ–‡æ¡£ä¸Šä¼ ** | [requirements.py](../backend/app/api/v1/endpoints/requirements.py) | APIç«¯ç‚¹ | `create_requirement` |
| **æ–‡æ¡£è§£æ** | [document_parser.py](../backend/app/services/document_parser.py) | å¤šæ ¼å¼è§£æ | `parse_document` |
| **å‘é‡åŒ–** | [document_embedding_service.py](../backend/app/services/document_embedding_service.py) | Milvuså­˜å‚¨ | `embed_document` |
| **MilvusæœåŠ¡** | [milvus_service.py](../backend/app/services/milvus_service.py) | å‘é‡æ•°æ®åº“ | `insert`, `search` |
| **æµ‹è¯•ç‚¹ç”Ÿæˆ** | [ai_service.py](../backend/app/services/ai_service.py) | LLMåˆ†æ | `extract_test_points` |
| **æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ** | [ai_service.py](../backend/app/services/ai_service.py) | RAGå¢å¼º | `generate_test_cases` |
| **RAGæœåŠ¡** | [rag_service.py](../backend/app/services/rag_service.py) | ä¸Šä¸‹æ–‡æ£€ç´¢ | `retrieve_context` |
| **å¹³å°é›†æˆ** | [automation_service.py](../backend/app/services/automation_service.py) | è‡ªåŠ¨åŒ–åˆ›å»º | `create_case_with_fields` |
| **WebSocket** | [websocket_service.py](../backend/app/services/websocket_service.py) | å®æ—¶é€šçŸ¥ | `broadcast` |

---

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### æ—¥å¿—é…ç½®

```python
import logging

# é…ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# å…³é”®èŠ‚ç‚¹è®°å½•
logger.info(f"æ–‡æ¡£è§£æå®Œæˆ: {file_name}, å†…å®¹é•¿åº¦={len(content)}")
logger.info(f"å‘é‡åŒ–å®Œæˆ: requirement_id={req_id}, ç‰‡æ®µæ•°={len(chunks)}")
logger.info(f"æµ‹è¯•ç‚¹ç”Ÿæˆ: requirement_id={req_id}, æ•°é‡={len(points)}, è€—æ—¶={elapsed:.2f}ç§’")
```

### æ€§èƒ½ç›‘æ§

```python
import time

def performance_monitor(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start_time

        logger.info(f"{func.__name__} æ‰§è¡Œå®Œæˆ, è€—æ—¶={elapsed:.2f}ç§’")
        return result
    return wrapper

@performance_monitor
def extract_test_points(requirement_id):
    # ...
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](QUICK_START.md)
- [ç³»ç»Ÿæ¶æ„](ARCHITECTURE.md)
- [å¤šæ¨¡å‹é…ç½®](MULTI_MODEL_CONFIG.md)
- [AIé€‰æ‹©è¶…æ—¶ä¿®å¤](AI_SELECTION_TIMEOUT_FIX.md)
- [æµ‹è¯•æ•°æ®ç”Ÿæˆ](TEST_DATA_GENERATION.md)
- [é—®é¢˜æ’æŸ¥æŒ‡å—](TROUBLESHOOTING.md)

---

## â“ å¸¸è§é—®é¢˜

### Q1: æ–‡æ¡£è§£æå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: ç³»ç»Ÿæœ‰ä¸‰å±‚å›é€€æœºåˆ¶:
1. æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦æ”¯æŒ (DOCX/PDF/TXT/XLS/XLSX)
2. æŸ¥çœ‹æ—¥å¿—ï¼Œç¡®è®¤å…·ä½“é”™è¯¯
3. å°è¯•è½¬æ¢ä¸ºTXTæ ¼å¼åé‡æ–°ä¸Šä¼ 

### Q2: å‘é‡åŒ–é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**A**:
1. æ£€æŸ¥ç¡…åŸºæµåŠ¨APIé…é¢
2. è°ƒæ•´ `CHUNK_SIZE` å‚æ•° (é»˜è®¤500)
3. ç›‘æ§ `batch_size` åŠ¨æ€è°ƒæ•´æ—¥å¿—

### Q3: AIç”Ÿæˆçš„æµ‹è¯•ç‚¹ä¸å‡†ç¡®ï¼Ÿ

**A**:
1. æ£€æŸ¥éœ€æ±‚æ–‡æ¡£è´¨é‡ï¼Œè¡¥å……è¯¦ç»†ä¿¡æ¯
2. åœ¨ `system_config` è¡¨è‡ªå®šä¹‰ `TEST_POINT_PROMPT`
3. è°ƒæ•´æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ (å¦‚ GPT-4)

### Q4: è‡ªåŠ¨åŒ–å¹³å°é›†æˆå¤±è´¥ï¼Ÿ

**A**:
1. æ£€æŸ¥ `AUTOMATION_PLATFORM_API_BASE` é…ç½®
2. æŸ¥çœ‹ API è¿æ¥æ—¥å¿—
3. ç¡®è®¤åœºæ™¯IDå’Œç”¨ä¾‹æ¨¡æ¿æ˜¯å¦å­˜åœ¨

---

**æ–‡æ¡£ç»“æŸ**