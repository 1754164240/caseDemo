# 多模型配置 - 快速开始指南

## 5 分钟快速上手

### 第一步: 运行数据库迁移 (1 分钟)

**Windows 用户:**
```bash
bat\create-model-configs-table.bat
```

**其他系统:**
```bash
cd backend
python -m scripts.create_model_configs_table
```

**预期输出:**
```
================================================================================
创建 model_configs 表并迁移现有配置
================================================================================

步骤 1: 创建 model_configs 表...
✅ model_configs 表创建成功
✅ 表验证成功

步骤 2: 检查并迁移现有模型配置...
✅ 已迁移现有配置为默认模型
   - API Base: https://api-inference.modelscope.cn/v1
   - Model Name: deepseek-ai/DeepSeek-V3.1

步骤 3: 当前模型配置列表:

ID    Name                 Display Name                   Model Name                     Default    Active    
-------------------------------------------------------------------------------------------------------------------
1     default              默认模型配置                    deepseek-ai/DeepSeek-V3.1      是         是        

================================================================================
完成
================================================================================
```

### 第二步: 启动服务 (1 分钟)

**启动后端:**
```bash
cd backend
python -m scripts.main
```

**启动前端:**
```bash
cd frontend
npm run dev
```

### 第三步: 访问模型配置页面 (1 分钟)

1. 打开浏览器访问: `http://localhost:5173`
2. 使用超级管理员账号登录
3. 点击左侧菜单的 **"系统管理"**
4. 点击 **"模型配置"** 标签页

### 第四步: 添加新模型 (2 分钟)

1. 点击右上角 **"添加模型配置"** 按钮

2. 填写表单:

**示例 1: OpenAI GPT-4**
```
配置名称: openai-gpt4
显示名称: OpenAI GPT-4
API Key: sk-proj-xxxxxxxxxxxxx
API Base URL: https://api.openai.com/v1
模型名称: gpt-4
提供商: openai
```

**示例 2: ModelScope Qwen**
```
配置名称: modelscope-qwen
显示名称: ModelScope Qwen2.5
API Key: ms-xxxxxxxxxxxxx
API Base URL: https://api-inference.modelscope.cn/v1
模型名称: Qwen/Qwen2.5-72B-Instruct
提供商: modelscope
```

3. 点击 **"确定"** 保存

### 第五步: 设置默认模型 (30 秒)

1. 在配置列表中找到要设为默认的模型
2. 点击该行的 **星标图标** ⭐
3. 看到 "默认模型已更新" 提示即成功

## 常用操作

### 编辑模型配置

1. 点击配置行的 **"编辑"** 按钮
2. 修改需要的字段
3. 点击 **"确定"** 保存

### 删除模型配置

1. 点击配置行的 **"删除"** 按钮
2. 确认删除

**注意:** 不能删除默认模型,需要先设置其他模型为默认

### 查看 API Key

- **列表中**: 自动脱敏显示 (如: `sk-p***abc`)
- **编辑时**: 显示完整 API Key

## 验证配置是否生效

### 方法 1: 生成测试点

1. 上传一个需求文档
2. 点击 "生成测试点"
3. 系统会使用默认模型生成测试点

### 方法 2: 知识库问答

1. 进入 "知识问答" 页面
2. 提问一个问题
3. 系统会使用默认模型回答

### 方法 3: 查看后端日志

后端日志会显示使用的模型信息:
```
[INFO] 使用模型配置: openai-gpt4
[INFO] 模型名称: gpt-4
[INFO] API Base: https://api.openai.com/v1
```

## 常见问题

### Q: 迁移脚本报错 "数据库连接失败"

**A:** 确保 PostgreSQL 数据库服务正在运行,并检查 `backend/.env` 中的数据库连接配置。

### Q: 看不到 "模型配置" 菜单

**A:** 只有超级管理员可以看到此菜单。确保使用的是超级管理员账号登录。

### Q: 添加配置后没有生效

**A:** 确保:
1. 配置已启用 (状态显示为 "启用")
2. 已设置为默认模型 (显示金色星标)
3. API Key 和 API Base URL 正确

### Q: 如何测试新配置是否可用?

**A:** 目前需要设为默认模型后,通过生成测试点或问答来验证。未来版本会添加配置测试功能。

### Q: 可以同时使用多个模型吗?

**A:** 当前版本系统使用默认模型。未来版本可能支持场景化模型选择。

## 配置示例

### OpenAI 官方 API

```yaml
配置名称: openai-gpt4
显示名称: OpenAI GPT-4
API Key: sk-proj-xxxxxxxxxxxxx
API Base URL: https://api.openai.com/v1
模型名称: gpt-4
提供商: openai
温度参数: 0.7
```

### ModelScope DeepSeek

```yaml
配置名称: modelscope-deepseek
显示名称: ModelScope DeepSeek V3.1
API Key: ms-xxxxxxxxxxxxx
API Base URL: https://api-inference.modelscope.cn/v1
模型名称: deepseek-ai/DeepSeek-V3.1
提供商: modelscope
温度参数: 0.7
```

### Azure OpenAI

```yaml
配置名称: azure-gpt4
显示名称: Azure GPT-4
API Key: your-azure-api-key
API Base URL: https://your-resource.openai.azure.com/
模型名称: gpt-4
提供商: azure
温度参数: 0.7
```

### 本地 Ollama

```yaml
配置名称: ollama-llama2
显示名称: Ollama Llama2
API Key: ollama
API Base URL: http://localhost:11434/v1
模型名称: llama2
提供商: custom
温度参数: 0.7
```

## 下一步

- 📖 阅读完整文档: `doc/多模型配置功能说明.md`
- 🧪 查看测试指南: `doc/多模型配置测试指南.md`
- 📝 查看实现总结: `doc/多模型配置实现总结.md`

## 获取帮助

如果遇到问题:
1. 查看 `doc/TROUBLESHOOTING.md`
2. 检查后端日志
3. 查看浏览器控制台错误信息

## 反馈和建议

欢迎提供反馈和改进建议!

