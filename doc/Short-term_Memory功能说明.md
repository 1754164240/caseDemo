# LangChain Short-term Memory åŠŸèƒ½è¯´æ˜

## âœ… åŠŸèƒ½å·²å®ç°!

### åŠŸèƒ½æè¿°
å®ç°äº† LangChain çš„ Short-term Memory (çŸ­æœŸè®°å¿†) åŠŸèƒ½,æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç†è§£ã€‚AI èƒ½å¤Ÿè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹,ç†è§£ä»£è¯å¼•ç”¨å’Œä¸Šä¸‹æ–‡å…³ç³»ã€‚

### æ ¸å¿ƒç‰¹æ€§

#### 1. **å¯¹è¯å†å²ç®¡ç†** âœ…
- å‰ç«¯è‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²
- æ¯æ¬¡æé—®æ—¶å‘é€å®Œæ•´å¯¹è¯å†å²
- æ”¯æŒæ— é™è½®å¯¹è¯

#### 2. **ä¸Šä¸‹æ–‡ç†è§£** âœ…
- AI èƒ½ç†è§£ä»£è¯å¼•ç”¨ (å¦‚ "å®ƒ"ã€"è¿™ä¸ª"ã€"é‚£ä¸ª")
- AI èƒ½ç†è§£ä¸Šä¸‹æ–‡å…³ç³» (å¦‚ "ç¬¬ä¸€ç§"ã€"åˆšæ‰æåˆ°çš„")
- AI èƒ½åŸºäºå†å²å¯¹è¯æä¾›è¿è´¯å›ç­”

#### 3. **RAG + Memory** âœ…
- ç»“åˆçŸ¥è¯†åº“æ£€ç´¢å’Œå¯¹è¯å†å²
- ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“å†…å®¹,è¾…ä»¥å¯¹è¯å†å²ç†è§£
- å³ä½¿çŸ¥è¯†åº“ä¸ºç©º,ä¹Ÿèƒ½åŸºäºå¯¹è¯å†å²å›ç­”

---

## å®ç°åŸç†

### 1. LangChain æ¶ˆæ¯æ ¼å¼

ä½¿ç”¨ LangChain çš„æ ‡å‡†æ¶ˆæ¯ç±»å‹:

```python
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage

# ç”¨æˆ·æ¶ˆæ¯
HumanMessage(content="ä»€ä¹ˆæ˜¯ä¿é™©?")

# AI æ¶ˆæ¯
AIMessage(content="ä¿é™©æ˜¯ä¸€ç§é£é™©ç®¡ç†å·¥å…·...")
```

### 2. Prompt æ¨¡æ¿æ”¯æŒå¯¹è¯å†å²

ä½¿ç”¨ `MessagesPlaceholder` æ’å…¥å¯¹è¯å†å²:

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# æœ‰å¯¹è¯å†å²çš„ Prompt
qa_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿é™©è¡Œä¸šçŸ¥è¯†åŠ©æ‰‹ã€‚
    
ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

è¯·æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå¯¹è¯å†å²å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""),
    MessagesPlaceholder(variable_name="chat_history"),  # æ’å…¥å¯¹è¯å†å²
    ("human", "{question}"),
])

# æ ¼å¼åŒ–æ¶ˆæ¯
messages = qa_prompt.format_messages(
    context=context,
    chat_history=history_messages,  # ä¼ å…¥å¯¹è¯å†å²
    question=question
)
```

### 3. å¯¹è¯å†å²è§£æ

å°†å‰ç«¯å‘é€çš„å¯¹è¯å†å²è½¬æ¢ä¸º LangChain æ¶ˆæ¯:

```python
def _parse_chat_history(self, chat_history: Optional[List[Dict[str, str]]]) -> List[BaseMessage]:
    """
    è§£æå¯¹è¯å†å²ä¸º LangChain æ¶ˆæ¯æ ¼å¼
    
    Args:
        chat_history: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
    
    Returns:
        [HumanMessage(...), AIMessage(...), ...]
    """
    if not chat_history:
        return []
    
    messages = []
    for msg in chat_history:
        role = msg.get("role", "")
        content = msg.get("content", "")
        
        if role == "user":
            messages.append(HumanMessage(content=content))
        elif role == "assistant":
            messages.append(AIMessage(content=content))
    
    return messages
```

---

## ä½¿ç”¨ç¤ºä¾‹

### åœºæ™¯ 1: ä»£è¯å¼•ç”¨ç†è§£

```
ç”¨æˆ·: ä»€ä¹ˆæ˜¯ä¿é™©?
AI: ä¿é™©æ˜¯ä¸€ç§é£é™©ç®¡ç†å·¥å…·,é€šè¿‡ç¼´çº³ä¿è´¹æ¥è½¬ç§»é£é™©...

ç”¨æˆ·: å®ƒæœ‰å“ªäº›ç±»å‹?  â† "å®ƒ" æŒ‡ä»£ "ä¿é™©"
AI: ä¿é™©ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ç±»å‹:
    1. äººå¯¿ä¿é™©
    2. è´¢äº§ä¿é™©
    3. å¥åº·ä¿é™©
    ...
```

**å…³é”®ç‚¹**: AI èƒ½ç†è§£ "å®ƒ" æŒ‡çš„æ˜¯ä¸Šä¸€è½®å¯¹è¯ä¸­çš„ "ä¿é™©"

---

### åœºæ™¯ 2: ä¸Šä¸‹æ–‡å…³ç³»ç†è§£

```
ç”¨æˆ·: æŠ•ä¿æµç¨‹æ˜¯ä»€ä¹ˆ?
AI: æŠ•ä¿æµç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤:
    1. å¡«å†™æŠ•ä¿ç”³è¯·ä¹¦
    2. æäº¤å¥åº·å‘ŠçŸ¥
    3. æ ¸ä¿å®¡æ ¸
    4. ç¼´çº³ä¿è´¹
    5. ç”Ÿæˆä¿å•

ç”¨æˆ·: ç¬¬äºŒæ­¥éœ€è¦æ³¨æ„ä»€ä¹ˆ?  â† "ç¬¬äºŒæ­¥" æŒ‡ä»£ "æäº¤å¥åº·å‘ŠçŸ¥"
AI: æäº¤å¥åº·å‘ŠçŸ¥æ—¶éœ€è¦æ³¨æ„:
    1. å¦‚å®å‘ŠçŸ¥å¥åº·çŠ¶å†µ
    2. ä¸å¾—éšç’æ—¢å¾€ç—…å²
    ...
```

**å…³é”®ç‚¹**: AI èƒ½ç†è§£ "ç¬¬äºŒæ­¥" æŒ‡çš„æ˜¯ä¸Šä¸€è½®å›ç­”ä¸­çš„ "æäº¤å¥åº·å‘ŠçŸ¥"

---

### åœºæ™¯ 3: å¤šè½®è¿½é—®

```
ç”¨æˆ·: ä¿å•å˜æ›´éœ€è¦å¤šé•¿æ—¶é—´?
AI: ä¿å•å˜æ›´éœ€è¦ 3-5 ä¸ªå·¥ä½œæ—¥ã€‚

ç”¨æˆ·: å¦‚æœåŠ æ€¥å‘¢?  â† ç»§ç»­è¿½é—®
AI: å¦‚æœéœ€è¦åŠ æ€¥å¤„ç†,å¯ä»¥ç”³è¯·ç‰¹æ®Šé€šé“,é€šå¸¸ 1-2 ä¸ªå·¥ä½œæ—¥å³å¯å®Œæˆ...

ç”¨æˆ·: éœ€è¦é¢å¤–è´¹ç”¨å—?  â† ç»§ç»­è¿½é—®
AI: åŠ æ€¥æœåŠ¡é€šå¸¸éœ€è¦æ”¯ä»˜ä¸€å®šçš„åŠ æ€¥è´¹ç”¨,å…·ä½“é‡‘é¢æ ¹æ®...
```

**å…³é”®ç‚¹**: AI èƒ½ç†è§£æ¯ä¸€è½®é—®é¢˜éƒ½æ˜¯åŸºäºä¹‹å‰çš„å¯¹è¯å†…å®¹

---

## æŠ€æœ¯å®ç°

### åç«¯å®ç°

#### 1. RAG æœåŠ¡ (`backend/app/services/rag_service.py`)

**æ·»åŠ å¯¹è¯å†å²è§£ææ–¹æ³•**:
```python
def _parse_chat_history(self, chat_history: Optional[List[Dict[str, str]]]) -> List[BaseMessage]:
    """è§£æå¯¹è¯å†å²ä¸º LangChain æ¶ˆæ¯æ ¼å¼"""
    if not chat_history:
        return []
    
    messages = []
    for msg in chat_history:
        role = msg.get("role", "")
        content = msg.get("content", "")
        
        if role == "user":
            messages.append(HumanMessage(content=content))
        elif role == "assistant":
            messages.append(AIMessage(content=content))
    
    return messages
```

**ä¿®æ”¹ query æ–¹æ³•æ”¯æŒå¯¹è¯å†å²**:
```python
def query(
    self,
    question: str,
    collection_name: str = "knowledge_base",
    top_k: int = 5,
    return_source: bool = True,
    stream: bool = False,
    chat_history: Optional[List[Dict[str, str]]] = None  # æ–°å¢å‚æ•°
) -> Dict[str, Any]:
    # è§£æå¯¹è¯å†å²
    history_messages = self._parse_chat_history(chat_history)
    
    # åˆ›å»ºæ”¯æŒå¯¹è¯å†å²çš„ Prompt
    if history_messages:
        qa_prompt = ChatPromptTemplate.from_messages([
            ("system", "..."),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}"),
        ])
        messages = qa_prompt.format_messages(
            context=context,
            chat_history=history_messages,
            question=question
        )
    else:
        # æ— å¯¹è¯å†å²çš„ Prompt
        ...
```

#### 2. API Schema (`backend/app/schemas/knowledge_base.py`)

**æ·»åŠ å¯¹è¯æ¶ˆæ¯ Schema**:
```python
class ChatMessage(BaseModel):
    """å¯¹è¯æ¶ˆæ¯"""
    role: str  # "user" æˆ– "assistant"
    content: str

class QuestionRequest(BaseModel):
    """é—®ç­”è¯·æ±‚ (æ”¯æŒå¯¹è¯å†å²)"""
    question: str
    collection_name: str = "knowledge_base"
    top_k: int = 5
    return_source: bool = True
    chat_history: Optional[List[ChatMessage]] = None  # å¯¹è¯å†å²
```

#### 3. API æ¥å£ (`backend/app/api/v1/endpoints/knowledge_base.py`)

**ä¿®æ”¹æŸ¥è¯¢æ¥å£ä¼ é€’å¯¹è¯å†å²**:
```python
@router.post("/query/stream")
async def query_knowledge_base_stream(
    request: QuestionRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    # è½¬æ¢å¯¹è¯å†å²ä¸ºå­—å…¸æ ¼å¼
    chat_history = None
    if request.chat_history:
        chat_history = [
            {"role": msg.role, "content": msg.content}
            for msg in request.chat_history
        ]
    
    # ä½¿ç”¨ RAG æœåŠ¡æµå¼æŸ¥è¯¢
    rag_service = RAGService(db)
    stream_gen = rag_service.query(
        question=request.question,
        collection_name=request.collection_name,
        top_k=request.top_k,
        return_source=request.return_source,
        stream=True,
        chat_history=chat_history  # ä¼ é€’å¯¹è¯å†å²
    )
```

---

### å‰ç«¯å®ç°

#### ä¿®æ”¹çŸ¥è¯†é—®ç­”é¡µé¢ (`frontend/src/pages/KnowledgeBase.tsx`)

**å‘é€å¯¹è¯å†å²**:
```typescript
const handleAsk = async () => {
  // æ„å»ºå¯¹è¯å†å² (åªå‘é€æœ€è¿‘çš„æ¶ˆæ¯,ä¸åŒ…æ‹¬å½“å‰é—®é¢˜)
  const chatHistory = messages.map(msg => ({
    role: msg.type === 'user' ? 'user' : 'assistant',
    content: msg.content,
  }))

  const response = await fetch('/api/v1/knowledge-base/query/stream', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`,
    },
    body: JSON.stringify({
      question: userQuestion,
      collection_name: 'knowledge_base',
      top_k: 5,
      return_source: true,
      chat_history: chatHistory,  // å‘é€å¯¹è¯å†å²
    }),
  })
}
```

---

## æµ‹è¯•æ–¹æ³•

### æ–¹æ³• 1: ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
cd backend
python -m scripts.test_memory
```

**æµ‹è¯•åœºæ™¯**:
1. ç¬¬ 1 è½®: "ä»€ä¹ˆæ˜¯ä¿é™©?"
2. ç¬¬ 2 è½®: "å®ƒæœ‰å“ªäº›ç±»å‹?" (å¼•ç”¨ "ä¿é™©")
3. ç¬¬ 3 è½®: "ç¬¬ä¸€ç§ç±»å‹çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆ?" (å¼•ç”¨ä¸Šä¸€è½®çš„å›ç­”)

**é¢„æœŸç»“æœ**:
- âœ… AI èƒ½æ­£ç¡®ç†è§£ "å®ƒ" æŒ‡ä»£ "ä¿é™©"
- âœ… AI èƒ½æ­£ç¡®ç†è§£ "ç¬¬ä¸€ç§ç±»å‹" æŒ‡ä»€ä¹ˆ
- âœ… å›ç­”è¿è´¯,ç¬¦åˆä¸Šä¸‹æ–‡

---

### æ–¹æ³• 2: æµè§ˆå™¨æµ‹è¯•

1. **è®¿é—®çŸ¥è¯†é—®ç­”é¡µé¢**
   - http://localhost:5173
   - ç™»å½• (admin / admin123)
   - ç‚¹å‡» "çŸ¥è¯†é—®ç­”"

2. **æµ‹è¯•å¤šè½®å¯¹è¯**
   ```
   ç¬¬ 1 è½®: ä»€ä¹ˆæ˜¯ä¿é™©?
   ç¬¬ 2 è½®: å®ƒæœ‰å“ªäº›ç±»å‹?
   ç¬¬ 3 è½®: ç¬¬ä¸€ç§ç±»å‹çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆ?
   ```

3. **è§‚å¯Ÿæ•ˆæœ**
   - âœ… AI èƒ½ç†è§£ä»£è¯å¼•ç”¨
   - âœ… AI èƒ½ç†è§£ä¸Šä¸‹æ–‡å…³ç³»
   - âœ… å›ç­”è¿è´¯è‡ªç„¶

---

## å¯¹è¯å†å²ç®¡ç†ç­–ç•¥

### å½“å‰ç­–ç•¥: å‘é€å…¨éƒ¨å†å²

**ä¼˜ç‚¹**:
- å®ç°ç®€å•
- ä¸Šä¸‹æ–‡å®Œæ•´

**ç¼ºç‚¹**:
- Token æ¶ˆè€—å¤§
- å¯èƒ½è¶…å‡ºæ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶

### ä¼˜åŒ–ç­–ç•¥ (å¯é€‰)

#### 1. **é™åˆ¶å†å²é•¿åº¦**
```typescript
// åªå‘é€æœ€è¿‘ N è½®å¯¹è¯
const MAX_HISTORY_ROUNDS = 5
const chatHistory = messages.slice(-MAX_HISTORY_ROUNDS * 2).map(msg => ({
  role: msg.type === 'user' ? 'user' : 'assistant',
  content: msg.content,
}))
```

#### 2. **ä½¿ç”¨ LangChain ConversationBufferWindowMemory**
```python
from langchain.memory import ConversationBufferWindowMemory

# åªä¿ç•™æœ€è¿‘ k è½®å¯¹è¯
memory = ConversationBufferWindowMemory(k=5)
```

#### 3. **ä½¿ç”¨ LangChain ConversationSummaryMemory**
```python
from langchain.memory import ConversationSummaryMemory

# è‡ªåŠ¨æ€»ç»“å†å²å¯¹è¯,å‡å°‘ Token æ¶ˆè€—
memory = ConversationSummaryMemory(llm=llm)
```

---

## ç›¸å…³æ–‡ä»¶

- âœ… `backend/app/services/rag_service.py` - RAG æœåŠ¡æ”¯æŒå¯¹è¯å†å²
- âœ… `backend/app/schemas/knowledge_base.py` - æ·»åŠ  ChatMessage Schema
- âœ… `backend/app/api/v1/endpoints/knowledge_base.py` - API æ¥å£ä¼ é€’å¯¹è¯å†å²
- âœ… `frontend/src/pages/KnowledgeBase.tsx` - å‰ç«¯å‘é€å¯¹è¯å†å²
- âœ… `backend/scripts/test_memory.py` - æµ‹è¯•è„šæœ¬
- âœ… `doc/Short-term_MemoryåŠŸèƒ½è¯´æ˜.md` - åŠŸèƒ½æ–‡æ¡£

---

## ä¸‹ä¸€æ­¥

1. **æµ‹è¯•åŠŸèƒ½**: è¿è¡Œ `python -m scripts.test_memory` æµ‹è¯•å¯¹è¯å†å²åŠŸèƒ½
2. **æµè§ˆå™¨æµ‹è¯•**: åœ¨æµè§ˆå™¨ä¸­æµ‹è¯•å¤šè½®å¯¹è¯
3. **ä¼˜åŒ–ç­–ç•¥**: æ ¹æ®éœ€è¦å®ç°å¯¹è¯å†å²é•¿åº¦é™åˆ¶æˆ–æ€»ç»“åŠŸèƒ½

æ‰€æœ‰åŠŸèƒ½å·²å®ç°! ğŸ‰ ç°åœ¨æ”¯æŒ Short-term Memory å¤šè½®å¯¹è¯äº†! ğŸŠ
